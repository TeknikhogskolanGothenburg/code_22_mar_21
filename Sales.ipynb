{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment:\n",
    "    positive = \"POSITIVE\"\n",
    "    neutral = \"NEUTRAL\"\n",
    "    negative = \"NEGATIVE\"\n",
    "    \n",
    "\n",
    "class Review:\n",
    "    def __init__(self, text, score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = Sentiment.negative if score <= 2 else Sentiment.neutral if score <= 3 else Sentiment.positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_name = './data/Books_small.json'\n",
    "reviews = []\n",
    "with open(file_name, 'r') as in_file:\n",
    "    for line in in_file:\n",
    "        data = json.loads(line)\n",
    "        data['reviewText'] = data['reviewText'].replace(\"&#8217;\", \"'\") \n",
    "        reviews.append(Review(data['reviewText'], data['overall']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am not a regular Iron Man reader. This issue collects several issues of Iron Man for a two-part arc titled Stark Resilient. Earlier issues had Iron Man wiping out his own memory to protect his IP rights, but forgetting to do a backup. thus, when they revived him, there are gaps in his memory. This reminds me of the expected downtime of my own home computer...There are genuine gaps in his recall and sometimes, Tony fakes amnesia conveniently. His new armor is regenerated from his own tissue (whatever). It's a convenient way to don the suit. Pepper hankers for the same treatment. So his armor is frontline main battle tank stuff, and hers is logistics support vehicle stuff. Rhodey questions his own role in this new technology era (he doesn't get the instantaneous armor capability - why not?).Storyline is acceptable. The artwork sucks.\n"
     ]
    }
   ],
   "source": [
    "print(reviews[100].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_data, test_data = train_test_split(reviews, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670\n",
      "330\n"
     ]
    }
   ],
   "source": [
    "print(len(training_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = [review.text for review in training_data]\n",
    "train_y = [review.sentiment for review in training_data]\n",
    "\n",
    "test_x = [review.text for review in test_data]\n",
    "test_y = [review.sentiment for review in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":) 552\n",
      ":| 71\n",
      ":( 47\n"
     ]
    }
   ],
   "source": [
    "print(':)', train_y.count(Sentiment.positive))\n",
    "print(':|', train_y.count(Sentiment.neutral))\n",
    "print(':(', train_y.count(Sentiment.negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":) 283\n",
      ":| 32\n",
      ":( 15\n"
     ]
    }
   ],
   "source": [
    "print(':)', test_y.count(Sentiment.positive))\n",
    "print(':|', test_y.count(Sentiment.neutral))\n",
    "print(':(', test_y.count(Sentiment.negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "\n",
    "test_x_vectors = vectorizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7371\n"
     ]
    }
   ],
   "source": [
    "print(len(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf_svm = SVC(kernel='linear')\n",
    "clf_svm.fit(train_x_vectors, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result for Linear SVM: 0.8242424242424242\n"
     ]
    }
   ],
   "source": [
    "print(\"The result for Linear SVM:\", clf_svm.score(test_x_vectors, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment:\n",
    "    positive = \"POSITIVE\"\n",
    "    neutral = \"NEUTRAL\"\n",
    "    negative = \"NEGATIVE\"\n",
    "    \n",
    "\n",
    "class Review:\n",
    "    def __init__(self, text, score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = Sentiment.negative if score <= 2 else Sentiment.neutral if score <= 3 else Sentiment.positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in c:\\users\\joaki\\anaconda3\\lib\\site-packages (0.0.48)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from contractions) (0.0.21)\n",
      "Requirement already satisfied: pyahocorasick in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from textsearch>=0.0.21->contractions) (1.4.1)\n",
      "Requirement already satisfied: anyascii in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from textsearch>=0.0.21->contractions) (0.1.7)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    # Remove punctuation marks\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    # Remove words with numbers\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions\n",
    "\n",
    "def fix_text(text):\n",
    "    text = text.replace(\"&#8217;\", \"'\")\n",
    "    text = contractions.fix(text)\n",
    "    text = clean_text(text)\n",
    "    \n",
    "    stopwords = [word.strip() for word in open('./data/stopwords_en.txt')]\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords])\n",
    "    \n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_name = './data/Books_small.json'\n",
    "reviews = []\n",
    "with open(file_name, 'r') as in_file:\n",
    "    for line in in_file:\n",
    "        data = json.loads(line)\n",
    "        text = fix_text(data['reviewText']) \n",
    "        reviews.append(Review(text, data['overall']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regular iron man reader issue collects several issues iron man twopart arc titled stark resilient earlier issues iron man wiping memory protect ip rights forgetting backup thus revived gaps memory reminds expected downtime home computerthere genuine gaps recall sometimes tony fakes amnesia conveniently new armor regenerated tissue whatever convenient way suit pepper hankers treatment armor frontline main battle tank stuff logistics support vehicle stuff rhodey questions role new technology era get instantaneous armor capability notstoryline acceptable artwork sucks\n"
     ]
    }
   ],
   "source": [
    "print(reviews[100].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_data, test_data = train_test_split(reviews, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = [review.text for review in training_data]\n",
    "train_y = [review.sentiment for review in training_data]\n",
    "\n",
    "test_x = [review.text for review in test_data]\n",
    "test_y = [review.sentiment for review in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "\n",
    "test_x_vectors = vectorizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7806\n"
     ]
    }
   ],
   "source": [
    "print(len(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf_svm = SVC(kernel='linear')\n",
    "clf_svm.fit(train_x_vectors, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result for Linear SVM with cleanded data: 0.8151515151515152\n"
     ]
    }
   ],
   "source": [
    "print(\"The result for Linear SVM with cleanded data:\", clf_svm.score(test_x_vectors, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment:\n",
    "    positive = \"POSITIVE\"\n",
    "    neutral = \"NEUTRAL\"\n",
    "    negative = \"NEGATIVE\"\n",
    "    \n",
    "\n",
    "class Review:\n",
    "    def __init__(self, text, score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = Sentiment.negative if score <= 2 else Sentiment.neutral if score <= 3 else Sentiment.positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    # Remove punctuation marks\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    # Remove words with numbers\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions\n",
    "\n",
    "def fix_text(text):\n",
    "    text = text.replace(\"&#8217;\", \"'\")\n",
    "    text = contractions.fix(text)\n",
    "    text = clean_text(text)\n",
    "    \n",
    "    stopwords = [word.strip() for word in open('./data/stopwords_en.txt')]\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_name = './data/Books_small.json'\n",
    "reviews = []\n",
    "with open(file_name, 'r') as in_file:\n",
    "    for line in in_file:\n",
    "        data = json.loads(line)\n",
    "        #text = fix_text(data['reviewText']) \n",
    "        text = data['reviewText']\n",
    "        reviews.append(Review(text, data['overall']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_data, test_data = train_test_split(reviews, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = [review.text for review in training_data]\n",
    "train_y = [review.sentiment for review in training_data]\n",
    "\n",
    "test_x = [review.text for review in test_data]\n",
    "test_y = [review.sentiment for review in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "\n",
    "test_x_vectors = vectorizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_log = LogisticRegression(max_iter=1000)\n",
    "clf_log.fit(train_x_vectors, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result for Linear SVM with cleanded data: 0.8484848484848485\n"
     ]
    }
   ],
   "source": [
    "print(\"The result for Linear SVM with cleanded data:\", clf_log.score(test_x_vectors, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\joaki\\anaconda3\\lib\\site-packages (3.0.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from spacy) (2.24.0)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from spacy) (0.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from spacy) (50.3.1.post20201107)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from spacy) (4.50.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from spacy) (0.4.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from spacy) (3.0.1)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from spacy) (1.7.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from spacy) (2.0.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from spacy) (1.19.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from spacy) (0.7.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from spacy) (2.11.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from spacy) (20.4)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.2 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from spacy) (8.0.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from spacy) (2.4.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from spacy) (0.8.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n",
      "Requirement already satisfied: six in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: en-core-web-md==3.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.0.0/en_core_web_md-3.0.0-py3-none-any.whl#egg=en_core_web_md==3.0.0 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: spacy<3.1.0,>=3.0.0 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from en-core-web-md==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (4.50.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.19.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.0.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (0.8.2)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.7.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (50.3.1.post20201107)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.0.5)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.2 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (8.0.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.0.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (0.7.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.0.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (0.4.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.11.2)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (0.3.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.24.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (20.4)\n",
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.1.1)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (7.1.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.10)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.4.7)\n",
      "Requirement already satisfied: six in c:\\users\\joaki\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.15.0)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install spacy\n",
    "!{sys.executable} -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [nlp(text) for text in train_x]\n",
    "word_vectors = [doc.vector for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svm_wv = SVC(kernel='linear')\n",
    "clf_svm_wv.fit(word_vectors, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result for Linear SVM with Word Vectors: 0.8575757575757575\n"
     ]
    }
   ],
   "source": [
    "test_docs = [nlp(text) for text in test_x]\n",
    "test_word_vectors = [doc.vector for doc in test_docs]\n",
    "\n",
    "print(\"The result for Linear SVM with Word Vectors:\", clf_svm_wv.score(test_word_vectors, test_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
